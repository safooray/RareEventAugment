# -*- coding: utf-8 -*-
"""RareEvent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GMX5_JMq1ptOJIFBJGtNYvXSuQ53RQSK
"""

from sklearn.linear_model import LogisticRegression 
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
import pandas as pd
import numpy as np

"""## Helper Methods"""

def scale_datasets(scaler, train_set, to_scale):
  scaler = scaler().fit(train_set)
  res = []
  for dataset in to_scale:
    res.append(scaler.transform(dataset))
  return res

def display_results(precision_recall_fscore_support):
  disp_df = pd.DataFrame(data=precision_recall_fscore_support, columns=['Neg Class', 'Pos Class'], index=['Precision', 'Recall', 'F-score', 'support'])
  print(disp_df)


"""### Load Data"""

data_path = 'data/processminer-rare-event-detection-data-augmentation.xlsx'
data_file = pd.ExcelFile(data_path)
data = pd.read_excel(data_file, 'data-(b)-4-min-ahead-conse-rmvd')

"""### Train-Test-Validation Split"""

SEED = 0
DATA_SPLIT_PCT = 0.10
label_name = 'y-4min-ahead'

data = data.drop(['time', 'x28', 'x61'], axis=1)
df_train, df_test = train_test_split(data, test_size=DATA_SPLIT_PCT, random_state=SEED)
df_train, df_valid = train_test_split(df_train, test_size=DATA_SPLIT_PCT, random_state=SEED)
df_train_x = df_train.drop([label_name], axis=1)
df_valid_x = df_valid.drop([label_name], axis=1)
df_test_x = df_test.drop([label_name], axis=1)

classifier = LogisticRegression(class_weight='balanced', max_iter = 10000, penalty = 'l1', solver = 'saga', C = 0.01, verbose=100)

"""## No Augmentation"""

df_train_x_scaled, df_valid_x_scaled, df_test_x_scaled = scale_datasets(StandardScaler, df_train_x, [df_train_x, df_valid_x, df_test_x])

classifier.fit(df_train_x_scaled, df_train[label_name])
y_hat_valid = classifier.predict(df_valid_x_scaled)
y_hat_train = classifier.predict(df_train_x_scaled)
print(precision_recall_fscore_support(df_valid[label_name], y_hat_valid))
precision_recall_fscore_support(df_train[label_name], y_hat_train)

"""## Data augmentation by adding noise."""

#def augment_noise(data_df):
data_df = df_train
data_df_x_1 = data_df[data_df[label_name] == 1].drop([label_name], axis=1)
noise_matrix = pd.DataFrame(data=np.random.normal(loc=0, scale=0.1, size=data_df_x_1.shape), index=data_df_x_1.index, columns=data_df_x_1.columns)
data_with_noise = data_df_x_1 + noise_matrix

augmented_train_x = pd.concat([pd.DataFrame(df_train_x_scaled, index=df_train_x.index, columns=df_train_x.columns),data_with_noise], axis=0)
augmented_train_y = pd.concat([df_train[label_name], pd.DataFrame(np.ones(shape=data_df_x_1.shape[0]))], axis=0)
augmented_train_x_rescaled = scale_datasets(StandardScaler, augmented_train_x, [augmented_train_x])[0]

classifier.fit(augmented_train_x_rescaled, augmented_train_y)
y_hat_valid = classifier.predict(df_valid_x_scaled)
y_hat_train = classifier.predict(augmented_train_x_rescaled)
val_res = precision_recall_fscore_support(df_valid[label_name], y_hat_valid)
train_res = precision_recall_fscore_support(augmented_train_y, y_hat_train)
display_results(train_res)
display_results(val_res)

